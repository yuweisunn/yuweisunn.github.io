<html>
<meta name="viewport" content="width=device-width, initial-scale=1">
<head>

<link rel="icon" href="css/icon.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet" />
<link href='https://unpkg.com/css.gg@2.0.0/icons/css/dark-mode.css' rel='stylesheet'>

<button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>


<style>
.content {
  max-width: 50%;
  margin: auto;
  text-align: justify;
}

.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 100%;
}


h2{color:#990000}

h3{color:#990000}

h4{color:#990000}

#myBtn {
  display: none; /* Hidden by default */
  position: fixed; /* Fixed/sticky position */
  bottom: 20px; /* Place the button at the bottom of the page */
  right: 30px; /* Place the button 30px from the right */
  z-index: 99; /* Make sure it does not overlap */
  border: none; /* Remove borders */
  outline: none; /* Remove outline */
  background-color: #990000; /* Set a background color */
  color: white; /* Text color */
  cursor: pointer; /* Add a mouse pointer on hover */
  padding: 10px; /* Some padding */
  border-radius: 10px; /* Rounded corners */
  font-size: 18px; /* Increase font size */
}

#myBtn:hover {
  background-color: #555; /* Add a dark-grey background on hover */
}

.dark-mode {
  background-color: black;
  color: white;
}

</style>


<script>
  // Math
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });


  // Get the button
  let mybutton = document.getElementById("myBtn");
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      mybutton.style.display = "block";
    } else {
      mybutton.style.display = "none";
    }
  }

  function topFunction() {
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
  }

  function myFunction() {
   var element = document.body;
   element.classList.toggle("dark-mode");
  }
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class ="content">
<title>The Modular Mind Blog</title>
<br>
<button onclick="myFunction()" class="gg-dark-mode" style="float: right;"></button>
<h1>The Modular Mind Blog</h1>
Created by <a href="https://yuweisunn.github.io/", style="text-decoration: none;"><b>Yuwei Sun</b></a>
<br><br>

<div class="row">
  <div class="leftcolumn">

    <div class="card">
      <a href="blog-5-31-24.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Continual Learning, Compositionality, and Modularity - Part &#8546</b></h2></a>
      <i>May 31, 2024</i>
      <p>Human reasoning identifies abstract patterns from few examples and generalizes them to new inputs through compositional and continual knowledge learning; infants initially learn words slowly but soon learn new words quickly, with this sophisticated pattern recognition extending to activities like planning and mathematics.</p>
    </div>

    <div class="card">
      <a href="blog-1-06-24.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Memory in Language Model-Enabled Agents</b></h2></a>
      <i>January 06, 2024</i>
      <p>Language models emerge as potential planners and world models for agents in virtual environments. This post delves into the unique capabilities of LLMs for decision-making and environmental understanding within simulated worlds.</p>
    </div>

    <div class="card">
      <a href="blog-10-01-23.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Memory: Natural and Artificial</b></h2></a>
      <i>October 01, 2023</i>
      <p>Intelligent agents use two learning systems - neocortex for structured knowledge and hippocampus for rapid experience learning. Hippocampus acts as an intermediary, preserving memories without disrupting neocortical knowledge. This post provides a literature review on natural memory to support our recent study on the Associative Transformer.</p>
    </div>

    <div class="card">
      <a href="blog-7-21-23.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Global Workspace Theory and System 2 AI - Part &#8545</b></h2></a>
      <i>July 21, 2023</i>
      <p>Global Workspace Theory (GWT) proposes that the brain operates as a network of specialized modules, with a central "global workspace" where selected information is integrated and broadcast. This post is about the alignment between the GWT and Transformer models, with a specific focus on the attention mechanism.</p>
    </div>

    <div class="card">
      <a href="blog-5-12-23.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>On the Versatility of Transformers</b></h2></a>
      <i>May 12, 2023</i>
      <p>Transformers are a type of neural network architecture that can model long-term dependencies and process sequences in parallel on GPUs. They lack inherent biases, making them flexible but requiring large amounts of training data to generalize well.</p>
    </div>

    <div class="card">
      <a href="blog-3-14-23.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Neural Network Approaches to the Binding Problem</b></h2></a>
      <i>March 14, 2023</i>
      <p>Contemporary neural networks struggle with flexible and dynamic information binding, and tend to learn surface statistics instead of underlying concepts. Attractor dynamics, such as Hopfield networks, are an approach to addressing representational dynamics in binding, using multiple stable equilibria that correspond to different decompositions of a scene.</p>
    </div>

    <div class="card">
      <a href="blog-1-10-23.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Continual Learning, Compositionality, and Modularity - Part &#8545</b></h2></a>
      <i>January 10, 2023</i>
      <p>Modular Neural Networks introduce sparsity in neuron connections between neural network layers. MNNs are divided into smaller, more manageable parts, they can be trained more efficiently and with fewer resources than a traditional, monolithic neural network.</p>
    </div>

    <div class="card">
      <a href="blog-12-22-22.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Continual Learning, Compositionality, and Modularity - Part &#8544</b></h2></a>
      <i>December 22, 2022</i>
      <p>Continual learning refers to the ability of an AI system to learn and adapt to new information and experiences over time, without forgetting previous knowledge. To achieve lifelong learning in AI systems, compositionality and modularity in neural networks have been intensively studied to overcome the challenges of catastrophic forgetting and data efficiency.</p>
    </div>

    <div class="card">
      <a href="blog-9-01-22.html" style="text-decoration: none;">
       <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Global Workspace Theory and System 2 AI - Part &#8544</b></h2></a>
      <i>September 01, 2022</i>
      <p>The global workspace theory demonstrates that in the human brain, multiple neural network models cooperate and compete in solving problems via a shared feature space for common knowledge sharing, which is called the global workspace (GW). Conscious attention selects which module and conscious content is gated through and remains available shortly in working memory.</p>
    </div>

    <div class="card">
      <a href="blog-7-10-22.html" style="text-decoration: none;">
         <hr attribute="value">  
      <h2 style="font-size:24px;"><b>Visual Question Answering</b></h2></a>
      <i>July 10, 2022</i>
      <p>Visual Question Answering (VQA) is a common problem in multimodal machine learning. Given an image and a question about the contents of the image, the VQA model is trained to answer the question correctly. These questions require an understanding of vision, language, and commonsense knowledge to answer. Several approaches such as Attention have been employed in VQA.</p>
    </div>
    
    <div class="card">
      <a href="blog-5-31-22.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Domain Shift and Transfer Learning</b></h2></a>
      <i>May 31, 2022</i>
      <p>One of the most challenging problems in decentralized AI is to improve the generality of the global model based on client data from different data domains. They are usually used for the same classification task but with particular sample features due to different data collection conditions of clients.</p>
    </div>

    <div class="card">
      <a href="blog-4-12-22.html" style="text-decoration: none;">
      <hr attribute="value"> 
      <h2 style="font-size:24px;"><b>Self-Supervised Learning and Multimodal Learning</b></h2></a>
      <i>April 12, 2022</i>
      <p>Information in the real world usually comes as different modalities. When searching for visual or audio content on the web, we can train a model leveraging any available collection of web data and index that type of media based on learned multimodal embeddings.</p>
    </div>

  </div>
</div>
</body>

<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=SjoXjmzE2E-uFeWnaJfYnyleA-K2V9qX2QWYZMbw5sY"></script>

<br>
<br>
<footer>
    <p>Created by Yuwei Sun. © 2024</p>
</footer>
<br>
</html>
